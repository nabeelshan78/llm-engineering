{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Transformer's Two Faces: Fine-Tuning for Classification and Conversation\n",
    "\n",
    "This notebook is a practical, hands-on to two of the most critical applications of fine-tuning in modern NLP. We explore how to adapt pre-trained Transformer models for vastly different goals: structured classification and open-ended text generation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Project Overview**\n",
    "\n",
    "We tackle two distinct fine-tuning challenges:\n",
    "\n",
    "1.  **Sentiment Analysis with BERT:** We fine-tune `bert-base-cased` on the Yelp Reviews dataset to build a powerful 5-star rating classifier. This demonstrates a classic supervised learning workflow using PyTorch's native training loop.\n",
    "\n",
    "2.  **Conversational AI with OPT:** We use the more advanced `SFTTrainer` from the TRL library to fine-tune a causal language model (`facebook/opt-350m`) on the OpenAssistant dataset. The goal is to transform a base generative model into a helpful conversational assistant, showing a clear \"before and after\" improvement in its ability to follow instructions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Technologies Demonstrated**\n",
    "\n",
    "* **Models:** BERT (Encoder), OPT (Decoder)\n",
    "* **Libraries:** PyTorch, Hugging Face `transformers`, `datasets`, and `trl`\n",
    "* **Tasks:** Multi-Class Classification, Causal Language Model Fine-Tuning\n",
    "* **Techniques:** Custom PyTorch training loop, `SFTTrainer`, Data Collators for instruction tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install torch==2.2.2\n",
    "# !pip install torchtext==0.17.2\n",
    "# !pip install portalocker==2.8.2\n",
    "# !pip install torchdata==0.7.1\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib==3.9.0 scikit-learn==1.5.0\n",
    "# !pip install numpy==1.26.0\n",
    "# !pip install transformers==4.42.1\n",
    "# !pip install datasets\n",
    "# !pip install torchmetrics==1.4.0.post0\n",
    "# !pip install accelerate==0.31.0\n",
    "# !pip install trl==0.9.4\n",
    "# !pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from trl import (\n",
    "    SFTConfig,                 \n",
    "    SFTTrainer,                \n",
    "    DataCollatorForCompletionOnlyLM\n",
    ")\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine-tuning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(1000)])\n",
    "dataset[\"test\"] = dataset[\"test\"].select([i for i in range(200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "print(tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122353da24814f76800c0609463d55bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89669903b23a495dbb923d80e4abb029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample 0 ---\n",
      "Label: 4\n",
      "--------------------\n",
      "Token           Input ID   Attention Mask\n",
      "=============================================\n",
      "[CLS]           101        1\n",
      "d               173        1\n",
      "##r             1197       1\n",
      ".               119        1\n",
      "gold            2284       1\n",
      "##berg          2953       1\n",
      "offers          3272       1\n",
      "everything      1917       1\n",
      "i               178        1\n",
      "look            1440       1\n",
      "for             1111       1\n",
      "in              1107       1\n",
      "a               170        1\n",
      "general         1704       1\n",
      "practitioner    22351      1\n",
      ".               119        1\n",
      "he              1119       1\n",
      "'               112        1\n",
      "s               188        1\n",
      "nice            3505       1\n",
      "and             1105       1\n",
      "easy            3123       1\n",
      "to              1106       1\n",
      "talk            2037       1\n",
      "to              1106       1\n",
      "without         1443       1\n",
      "being           1217       1\n",
      "patron          10063      1\n",
      "##izing         4404       1\n",
      ";               132        1\n",
      "he              1119       1\n",
      "'               112        1\n",
      "s               188        1\n",
      "always          1579       1\n",
      "on              1113       1\n",
      "time            1159       1\n",
      "in              1107       1\n",
      "seeing          3195       1\n",
      "his             1117       1\n",
      "patients        4420       1\n",
      ";               132        1\n",
      "he              1119       1\n",
      "'               112        1\n",
      "s               188        1\n",
      "affiliated      6559       1\n",
      "with            1114       1\n",
      "a               170        1\n",
      "top             1499       1\n",
      "-               118        1\n",
      "notch           23555      1\n",
      "hospital        2704       1\n",
      "(               113        1\n",
      "n               183        1\n",
      "##yu            9379       1\n",
      ")               114        1\n",
      "which           1134       1\n",
      "my              1139       1\n",
      "parents         2153       1\n",
      "have            1138       1\n",
      "explained       3716       1\n",
      "to              1106       1\n",
      "me              1143       1\n",
      "is              1110       1\n",
      "very            1304       1\n",
      "important       1696       1\n",
      "in              1107       1\n",
      "case            1692       1\n",
      "something       1380       1\n",
      "happens         5940       1\n",
      "and             1105       1\n",
      "you             1128       1\n",
      "need            1444       1\n",
      "surgery         6059       1\n",
      ";               132        1\n",
      "and             1105       1\n",
      "you             1128       1\n",
      "can             1169       1\n",
      "get             1243       1\n",
      "refer           5991       1\n",
      "##rals          16179      1\n",
      "to              1106       1\n",
      "see             1267       1\n",
      "specialists     18137      1\n",
      "without         1443       1\n",
      "having          1515       1\n",
      "to              1106       1\n",
      "see             1267       1\n",
      "him             1140       1\n",
      "first           1148       1\n",
      ".               119        1\n",
      "really          1541       1\n",
      ",               117        1\n",
      "what            1184       1\n",
      "more            1167       1\n",
      "do              1202       1\n",
      "you             1128       1\n",
      "need            1444       1\n",
      "?               136        1\n",
      "i               178        1\n",
      "'               112        1\n",
      "m               182        1\n",
      "sitting         2807       1\n",
      "here            1303       1\n",
      "trying          1774       1\n",
      "to              1106       1\n",
      "think           1341       1\n",
      "of              1104       1\n",
      "any             1251       1\n",
      "complaints      11344      1\n",
      "i               178        1\n",
      "have            1138       1\n",
      "about           1164       1\n",
      "him             1140       1\n",
      ",               117        1\n",
      "but             1133       1\n",
      "i               178        1\n",
      "'               112        1\n",
      "m               182        1\n",
      "really          1541       1\n",
      "drawing         4619       1\n",
      "a               170        1\n",
      "blank           9153       1\n",
      ".               119        1\n",
      "[SEP]           102        1\n",
      "\n",
      "... (padding tokens omitted)\n"
     ]
    }
   ],
   "source": [
    "sample = tokenized_datasets[\"train\"][0]\n",
    "tokens = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"])\n",
    "\n",
    "print(f\"--- Sample 0 ---\")\n",
    "print(f\"Label: {sample['labels']}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(f\"{'Token':<15} {'Input ID':<10} {'Attention Mask'}\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "for token, input_id, attention_mask in zip(tokens, sample[\"input_ids\"], sample[\"attention_mask\"]):\n",
    "    if token == '[PAD]':\n",
    "        print(\"\\n... (padding tokens omitted)\")\n",
    "        break\n",
    "    print(f\"{token:<15} {input_id:<10} {attention_mask}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=2)\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll load a pretrained classification model with 5 classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda=lambda current_step: (1 - current_step / num_training_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, tr_dataloader):\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    model.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0 \n",
    "\n",
    "        for batch in tr_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "        tr_losses.append(total_loss/len(tr_dataloader))\n",
    "        \n",
    "    plt.plot(tr_losses)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, evl_dataloader):\n",
    "    metric = Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in evl_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Accumulate the predictions and labels for the metric\n",
    "            metric(predictions, batch[\"labels\"])\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = metric.compute()\n",
    "    print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(model=model, tr_dataloader=train_dataloader)\n",
    "# torch.save(model, 'bert-classification-model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_gpt.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/HausLW2F_w30s1UK0zj7mQ/training-loss-BERT-Classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('bert-classification-model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26499998569488525\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning a more complex model that can generate conversations between a human and an assistant using SFTtrainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a conversational model using SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How fine-tuning a decoder transformer using a specific dataset affects the quality of the generated responses in a question-answering task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train split of \"timdettmers/openassistant-guanaco\" dataset from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a343bf7ca8541709f6f3b1a96763d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/395 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb4e96d0fa0498cb030f8e37700dd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openassistant_best_replies_train.jsonl:   0%|          | 0.00/20.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d525d32abb1403e86c0ea6af9a09bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "openassistant_best_replies_eval.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f46072f3761448a84cd0354cf29ac01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306357e93a774f069cbf0fb1209e1e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/518 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 9846\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained causal model \"facebook/opt-350m\" along with its tokenizer from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Human: What is the difference between open assistant and ChatGPT? Why should i use Open Assistant? And can you give me some examples of advanced chatbots that are similar to Open Assistant?### Assistant: First of all, a major difference is that Open Assistant is, as the name implies, open source. ChatGPT is closed source and might have more restrictions. \\n\\nOpen Assistant has less rules and restrictions than ChatGPT, and can be implemented into a multitude of applications. \\n\\nSome examples of similar chatbots are ChatGPT, Bing Chat, YouChat, Replit Ghostwriter, Character.ai, and Jasper, but there are many more.### Human: What is the difference in performance between the two models? Can you be more specific about the performance in conversational tasks, knowledge grounded question answering and in summarization?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[30]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f26185ace7465fa78f8d2af9b05515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/644 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d0f1bd989645808bba82e1891f44e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/663M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2faca398ace492f836903025910355d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eecc75bef794c8ea7ca7bfa2f409a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dabf044af2d493b9f24c638e7eb8e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71a514473f44ea7a5e39f68abba930a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb285f4ec93c4291be6d2912144f462c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instruction and response templates based on the train dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_template = \"### Human:\"\n",
    "response_template = \"### Assistant:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a collator to curate data in the appropriate shape for training using **\"DataCollatorForCompletionOnlyLM\"**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an SFTTrainer object and pass the model as well as the dataset and collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,  \n",
    "    per_device_eval_batch_size=2,  \n",
    "    max_seq_length=1024,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt the pretrained model with a specific question: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
      "\n",
      "The term \"monopsony\" is used in the context of the \"mono\" (mono-economy) model. The term \"mono-economy\" is used in the context of the \"mono-economy\" model. The term \"mono-economy\" is used in the context of\n"
     ]
    }
   ],
   "source": [
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the model is barely aware of what \"monopsony\" is in the context of economics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the difference between open assistant and ChatGPT? Why should i use Open Assistant? And can you give me \n",
      "some examples of advanced chatbots that are similar to Open Assistant?\n",
      "\n",
      "I'm not sure if Open Assistant is the same as ChatGPT, but I've used Open Assistant for a while and it's pretty good.\n",
      "\n",
      "Open Assistant is a chatbot that can be used to communicate with other chatbots. It's a chatbot that can be used to communicate with other chatbots.\n",
      "\n",
      "Chat\n"
     ]
    }
   ],
   "source": [
    "print(pipe('''What is the difference between open assistant and ChatGPT? Why should i use Open Assistant? And can you give me \n",
    "some examples of advanced chatbots that are similar to Open Assistant?''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the tuned model that i trained on a GPU: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Assistant_model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how the tuned model performs in answering the same specialized question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
      "\n",
      "The term \"monopsony\" in economics refers to the practice of controlling the working class by imposing a price on them. This can be seen as a form of economic control, but it can also be seen as a form of political control, as the price of a product can be influenced by the interests of the state.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use \n",
    "examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the difference between open assistant and ChatGPT? Why should i use Open Assistant? And can you give me \n",
      "some examples of advanced chatbots that are similar to Open Assistant?\n",
      "\n",
      "Open Assistant is a chatbot that uses a combination of AI and machine learning to generate text and generate responses. It is designed to be easy to use and to be able to understand and respond to user input. It is designed to be able to understand and respond to user input, and it can be used to generate text, generate responses,\n"
     ]
    }
   ],
   "source": [
    "print(pipe('''What is the difference between open assistant and ChatGPT? Why should i use Open Assistant? And can you give me \n",
    "some examples of advanced chatbots that are similar to Open Assistant?''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "a46cb4be48bad372e5cf1b1ca80ac3c279a2287fa4e1c50abe50c53d8edc661a"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
